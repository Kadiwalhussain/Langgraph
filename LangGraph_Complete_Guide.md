# LangGraph: The Complete Guide

## Table of Contents
1. [Introduction](#introduction)
2. [Why LangGraph Was Created](#why-langgraph-was-created)
3. [What is LangGraph](#what-is-langgraph)
4. [Core Concepts](#core-concepts)
5. [Architecture](#architecture)
6. [Key Features](#key-features)
7. [Components Deep Dive](#components-deep-dive)
8. [State Management](#state-management)
9. [Building Agents with LangGraph](#building-agents-with-langgraph)
10. [Advanced Patterns](#advanced-patterns)
11. [LangGraph vs Other Frameworks](#langgraph-vs-other-frameworks)
12. [Best Practices](#best-practices)
13. [Real-World Use Cases](#real-world-use-cases)
14. [Getting Started](#getting-started)
15. [Resources for Learning](#resources-for-learning)
---

## Introduction

**LangGraph** is a library built on top of LangChain, created specifically for building **stateful, multi-actor applications** using Large Language Models (LLMs). It provides a structured framework for designing complex, cyclical workflows that go beyond simple linear chains, allowing developers to build advanced AI agents and multi-agent systems with better control and flexibility.

**Created by:** LangChain (Harrison Chase and team)  
**First Release:** Late 2023  
**Current Status:** Actively maintained and rapidly evolving  
**License:** MIT License


---

## Why LangGraph Was Created

### The Problem with Traditional LLM Frameworks

Before LangGraph, developers faced several challenges:

#### 1. **Linear Chain Limitations**
Traditional LangChain focused on DAG (Directed Acyclic Graph) workflows:
- Chains were linear: Input â†’ Step 1 â†’ Step 2 â†’ Output
- No ability to loop back or create cycles
- Limited for complex reasoning that requires iteration

#### 2. **Lack of State Management**
- Previous frameworks had no built-in way to maintain state across multiple interactions
- Memory was basic and not integrated into the workflow structure
- Difficult to build agents that remember context within a task

#### 3. **Agent Limitations**
The original LangChain AgentExecutor had issues:
- Hard to customize agent behavior
- Difficult to add human-in-the-loop interactions
- Limited control over agent decision-making process
- No easy way to pause, resume, or checkpoint agents

#### 4. **Multi-Agent Coordination**
- No native support for multiple agents working together
- Difficult to orchestrate complex workflows with multiple actors
- Lack of structured communication between agents

### The Solution: LangGraph

LangGraph was created to address these limitations by providing:
- **Cyclic graph support** for iterative reasoning
- **First-class state management** built into the framework
- **Fine-grained control** over agent behavior
- **Human-in-the-loop** capabilities out of the box
- **Multi-agent orchestration** patterns
- **Persistence and streaming** support

---

## What is LangGraph

### Definition

LangGraph is a **graph-based orchestration framework** for building complex, stateful AI applications. It models your application as a **graph** where:
- **Nodes** represent units of work (functions, agents, tools)
- **Edges** represent the flow of control between nodes
- **State** flows through the graph and can be modified at each node

### Core Philosophy

```
"LangGraph is built on the principle that the most powerful AI applications 
require cycles, controllability, and persistence - things that simple 
chains cannot provide."
```

### Key Characteristics

| Feature | Description |
|---------|-------------|
| **Graph-Based** | Applications modeled as directed graphs |
| **Stateful** | Built-in state management across the entire workflow |
| **Cyclic** | Supports loops and iterative processes |
| **Controllable** | Fine-grained control over every step |
| **Persistent** | Built-in checkpointing and persistence |
| **Streamable** | Native support for streaming outputs |

---

## Core Concepts

### 1. State

State is the **central concept** in LangGraph. It represents all the data that flows through your graph.

```python
from typing import TypedDict, Annotated
from langgraph.graph import add_messages

class AgentState(TypedDict):
    messages: Annotated[list, add_messages]
    current_step: str
    iteration_count: int
    final_answer: str
```

**Key Points:**
- State is defined as a TypedDict or Pydantic model
- State is passed to every node in the graph
- Nodes return updates to state (not the full state)
- Reducers define how updates are merged

### 2. Nodes

Nodes are **functions** that perform work and return state updates.

```python
def agent_node(state: AgentState) -> dict:
    """Process the current state and return updates."""
    # Perform some work
    response = llm.invoke(state["messages"])
    
    # Return state updates
    return {
        "messages": [response],
        "current_step": "agent_complete"
    }
```

**Node Types:**
- **Regular Nodes**: Standard processing functions
- **Tool Nodes**: Execute tools based on agent decisions
- **Conditional Nodes**: Route based on conditions

### 3. Edges

Edges define the **flow of control** between nodes.

```python
# Simple edge: always go from A to B
graph.add_edge("node_a", "node_b")

# Conditional edge: route based on state
graph.add_conditional_edges(
    "agent",
    should_continue,  # Function that returns next node name
    {
        "continue": "tools",
        "end": END
    }
)
```

**Edge Types:**
- **Normal Edges**: Direct connection between nodes
- **Conditional Edges**: Dynamic routing based on state
- **Entry Points**: Where the graph starts
- **Finish Points**: Where the graph ends (END node)

### 4. Graph

The graph is the **container** that holds nodes and edges together.

```python
from langgraph.graph import StateGraph, END

# Create graph with state schema
graph = StateGraph(AgentState)

# Add nodes
graph.add_node("agent", agent_node)
graph.add_node("tools", tool_node)

# Add edges
graph.add_edge("__start__", "agent")
graph.add_conditional_edges("agent", router, {"continue": "tools", "end": END})
graph.add_edge("tools", "agent")

# Compile
app = graph.compile()
updating()
```

### 5. Checkpointing

LangGraph provides built-in **persistence** through checkpointers.

```python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
app = graph.compile(checkpointer=memory)

# Every invocation is saved
config = {"configurable": {"thread_id": "user_123"}}
result = app.invoke({"messages": [...]}, config)
```

---

## Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LangGraph Application                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚    State     â”‚â”€â”€â”€â–¶â”‚    Node A    â”‚â”€â”€â”€â–¶â”‚    Node B    â”‚       â”‚
â”‚  â”‚   Manager    â”‚    â”‚  (Function)  â”‚    â”‚  (Function)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                   â”‚                   â”‚                â”‚
â”‚         â”‚                   â–¼                   â”‚                â”‚
â”‚         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                â”‚
â”‚         â”‚            â”‚  Conditional â”‚           â”‚                â”‚
â”‚         â”‚            â”‚    Router    â”‚           â”‚                â”‚
â”‚         â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                â”‚
â”‚         â”‚                   â”‚                   â”‚                â”‚
â”‚         â–¼                   â–¼                   â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                   Checkpointer                        â”‚       â”‚
â”‚  â”‚          (Memory / SQLite / PostgreSQL)               â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Execution Flow

```
1. Graph receives input
         â”‚
         â–¼
2. State is initialized/restored from checkpoint
         â”‚
         â–¼
3. Entry node processes state
         â”‚
         â–¼
4. Router determines next node
         â”‚
         â–¼
5. Next node processes state (can loop back to step 4)
         â”‚
         â–¼
6. When END is reached, final state is returned
         â”‚
         â–¼
7. State is checkpointed for persistence
```

---

## Key Features

### 1. Cycles and Loops

Unlike DAG-based systems, LangGraph supports **cycles**:

```python
# Agent can loop back after tool execution
graph.add_edge("tools", "agent")  # Creates a cycle
```

**Use Cases:**
- ReAct-style agents that reason and act iteratively
- Self-correcting agents that retry on failure
- Multi-step reasoning processes

### 2. Controllability

**Fine-grained control** over every aspect:

```python
# Breakpoints for debugging
app = graph.compile(
    checkpointer=memory,
    interrupt_before=["tools"]  # Pause before tools execute
)

# Manual state updates
app.update_state(config, {"messages": [new_message]})
```

### 3. Human-in-the-Loop (HITL)

Built-in support for **human intervention**:

```python
# Interrupt for human approval
graph.add_node("human_approval", lambda state: None)
app = graph.compile(interrupt_before=["human_approval"])

# In your application
result = app.invoke(input, config)
# ... wait for human input ...
app.invoke(None, config)  # Resume with human input
```

### 4. Streaming

Multiple streaming modes:

```python
# Stream all outputs
for event in app.stream(input, stream_mode="values"):
    print(event)

# Stream updates only
for event in app.stream(input, stream_mode="updates"):
    print(event)

# Stream debug information
for event in app.stream(input, stream_mode="debug"):
    print(event)
```

### 5. Persistence

Multiple persistence backends:

```python
# Memory (development)
from langgraph.checkpoint.memory import MemorySaver

# SQLite (local persistence)
from langgraph.checkpoint.sqlite import SqliteSaver

# PostgreSQL (production)
from langgraph.checkpoint.postgres import PostgresSaver
```

### 6. Time Travel

**Navigate through state history**:

```python
# Get all states for a thread
states = list(app.get_state_history(config))

# Restore to a previous state
app.update_state(config, None, as_node=states[2].config)
```

---

## Components Deep Dive

### StateGraph

The main class for building graphs:

```python
from langgraph.graph import StateGraph, START, END

class MyState(TypedDict):
    messages: list
    data: dict

graph = StateGraph(MyState)

# Add nodes
graph.add_node("process", process_function)

# Set entry point
graph.add_edge(START, "process")

# Set exit point
graph.add_edge("process", END)

# Compile to runnable
app = graph.compile()
```

### MessageGraph

Specialized graph for chat applications:

```python
from langgraph.graph import MessageGraph

graph = MessageGraph()
graph.add_node("chatbot", chatbot_function)
graph.add_edge(START, "chatbot")
graph.add_edge("chatbot", END)
```

### Reducers

Control how state updates are merged:

```python
from langgraph.graph import add_messages
from operator import add

class State(TypedDict):
    # add_messages appends new messages
    messages: Annotated[list, add_messages]
    
    # operator.add concatenates lists
    items: Annotated[list, add]
    
    # No reducer = replace value
    current_node: str
```

**Built-in Reducers:**
- `add_messages`: Smart message merging (handles updates by ID)
- `operator.add`: List concatenation
- Custom functions for complex logic

### Prebuilt Components

LangGraph provides prebuilt components:

```python
from langgraph.prebuilt import create_react_agent, ToolNode

# Create a ReAct agent in one line
agent = create_react_agent(model, tools)

# Prebuilt tool execution node
tool_node = ToolNode(tools)
```

---

## State Management

### State Schema Definition

```python
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage

class AgentState(TypedDict):
    """Complete agent state schema."""
    
    # Messages with smart merging
    messages: Annotated[Sequence[BaseMessage], add_messages]
    
    # Simple values (replaced on update)
    current_agent: str
    step_count: int
    
    # Complex nested data
    context: dict
    
    # Optional fields
    error: str | None
```

### State Updates

Nodes return **partial updates**:

```python
def my_node(state: AgentState) -> dict:
    # Only return fields that changed
    return {
        "messages": [new_message],
        "step_count": state["step_count"] + 1
    }
```

### Private State

State that doesn't persist between graph runs:

```python
from langgraph.graph import StateGraph
from langgraph.managed import IsLastStep

class State(TypedDict):
    messages: list
    is_last_step: IsLastStep  # Managed value, not persisted
```

---

## Building Agents with LangGraph

### Basic ReAct Agent

```python
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

# Define tools
@tool
def search(query: str) -> str:
    """Search the web for information."""
    return f"Results for: {query}"

@tool
def calculator(expression: str) -> str:
    """Evaluate a math expression."""
    return str(eval(expression))

# Create agent
model = ChatOpenAI(model="gpt-4")
agent = create_react_agent(model, [search, calculator])

# Run agent
result = agent.invoke({
    "messages": [("user", "What is 25 * 4?")]
})
```

### Custom Agent from Scratch

```python
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage

class AgentState(TypedDict):
    messages: Annotated[list, add_messages]

def agent(state: AgentState):
    """The agent node that decides what to do."""
    response = model.bind_tools(tools).invoke(state["messages"])
    return {"messages": [response]}

def should_continue(state: AgentState):
    """Router function."""
    last_message = state["messages"][-1]
    if last_message.tool_calls:
        return "tools"
    return "end"

def tool_node(state: AgentState):
    """Execute tools."""
    outputs = []
    for tool_call in state["messages"][-1].tool_calls:
        result = tools_by_name[tool_call["name"]].invoke(tool_call["args"])
        outputs.append(ToolMessage(content=result, tool_call_id=tool_call["id"]))
    return {"messages": outputs}

# Build graph
graph = StateGraph(AgentState)
graph.add_node("agent", agent)
graph.add_node("tools", tool_node)

graph.add_edge("__start__", "agent")
graph.add_conditional_edges("agent", should_continue, {"tools": "tools", "end": END})
graph.add_edge("tools", "agent")

agent_app = graph.compile()
```

### Multi-Agent Systems

```python
class MultiAgentState(TypedDict):
    messages: Annotated[list, add_messages]
    current_agent: str
    task_complete: bool

def researcher(state):
    """Research agent."""
    # Research logic
    return {"messages": [response], "current_agent": "researcher"}

def writer(state):
    """Writing agent."""
    # Writing logic
    return {"messages": [response], "current_agent": "writer"}

def reviewer(state):
    """Review agent."""
    # Review logic
    return {"messages": [response], "current_agent": "reviewer"}

def router(state):
    """Route to next agent."""
    current = state["current_agent"]
    if current == "researcher":
        return "writer"
    elif current == "writer":
        return "reviewer"
    else:
        return "end"

# Build multi-agent graph
graph = StateGraph(MultiAgentState)
graph.add_node("researcher", researcher)
graph.add_node("writer", writer)
graph.add_node("reviewer", reviewer)

graph.add_edge("__start__", "researcher")
graph.add_conditional_edges("researcher", router, {"writer": "writer", "end": END})
graph.add_conditional_edges("writer", router, {"reviewer": "reviewer", "end": END})
graph.add_conditional_edges("reviewer", router, {"researcher": "researcher", "end": END})
```

---

## Advanced Patterns

### 1. Subgraphs

Compose graphs within graphs:

```python
# Define a subgraph
subgraph = StateGraph(SubState)
subgraph.add_node("process", process_fn)
subgraph.add_edge("__start__", "process")
subgraph.add_edge("process", "__end__")
compiled_subgraph = subgraph.compile()

# Use in parent graph
parent_graph = StateGraph(ParentState)
parent_graph.add_node("sub", compiled_subgraph)
```

### 2. Parallel Execution

Run nodes in parallel:

```python
from langgraph.graph import StateGraph

# Nodes with same source run in parallel
graph.add_edge("start", "node_a")
graph.add_edge("start", "node_b")
graph.add_edge("start", "node_c")

# All converge to next node
graph.add_edge("node_a", "combine")
graph.add_edge("node_b", "combine")
graph.add_edge("node_c", "combine")
```

### 3. Dynamic Node Creation

```python
def create_dynamic_graph(num_agents: int):
    graph = StateGraph(State)
    
    for i in range(num_agents):
        graph.add_node(f"agent_{i}", create_agent_node(i))
    
    # Add edges dynamically
    graph.add_edge("__start__", "agent_0")
    for i in range(num_agents - 1):
        graph.add_edge(f"agent_{i}", f"agent_{i+1}")
    graph.add_edge(f"agent_{num_agents-1}", END)
    
    return graph.compile()
```

### 4. Error Handling

```python
def safe_node(state):
    """Node with error handling."""
    try:
        result = risky_operation(state)
        return {"result": result, "error": None}
    except Exception as e:
        return {"error": str(e)}

def error_router(state):
    """Route based on error state."""
    if state.get("error"):
        return "error_handler"
    return "continue"
```

### 5. Retry Logic

```python
def retry_node(state):
    """Node with retry logic."""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            return {"result": operation(state)}
        except Exception as e:
            if attempt == max_retries - 1:
                return {"error": str(e)}
            time.sleep(2 ** attempt)  # Exponential backoff
```

### 6. Branching and Merging

```python
# Branch to multiple paths
def branch_router(state):
    if state["type"] == "A":
        return "path_a"
    elif state["type"] == "B":
        return "path_b"
    return "path_c"

graph.add_conditional_edges(
    "classifier",
    branch_router,
    {"path_a": "handler_a", "path_b": "handler_b", "path_c": "handler_c"}
)

# Merge back
graph.add_edge("handler_a", "merger")
graph.add_edge("handler_b", "merger")
graph.add_edge("handler_c", "merger")
```

---

## LangGraph vs Other Frameworks

### LangGraph vs LangChain (LCEL)

| Aspect | LangChain (LCEL) | LangGraph |
|--------|------------------|-----------|
| **Graph Type** | DAG only | Cyclic graphs |
| **State** | Implicit | Explicit, first-class |
| **Persistence** | Add-on | Built-in |
| **Human-in-loop** | Manual | Native support |
| **Complexity** | Simple chains | Complex workflows |
| **Use Case** | Linear pipelines | Agents, multi-step |

### LangGraph vs AutoGen

| Aspect | AutoGen | LangGraph |
|--------|---------|-----------|
| **Focus** | Multi-agent conversations | Graph-based workflows |
| **State** | Conversation-centric | Flexible state schema |
| **Control** | Agent-driven | Developer-controlled |
| **Persistence** | Limited | Full checkpoint system |
| **Debugging** | Harder | Time-travel debugging |

### LangGraph vs CrewAI

| Aspect | CrewAI | LangGraph |
|--------|--------|-----------|
| **Abstraction** | High-level roles | Low-level control |
| **Flexibility** | Opinionated | Very flexible |
| **Learning Curve** | Easier | Steeper |
| **Customization** | Limited | Extensive |
| **Use Case** | Quick prototypes | Production systems |

### When to Choose LangGraph

âœ… **Use LangGraph when:**
- You need cycles in your workflow
- State management is critical
- Human-in-the-loop is required
- You need fine-grained control
- Building production-ready agents
- Multi-agent coordination is complex

âŒ **Consider alternatives when:**
- Simple linear chain is sufficient
- Rapid prototyping without complexity
- You prefer higher-level abstractions

---

## Best Practices

### 1. State Design

```python
# âœ… Good: Clear, typed state
class WellDesignedState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    current_step: Literal["research", "write", "review"]
    iteration: int
    context: dict[str, Any]

# âŒ Bad: Ambiguous, untyped state
class PoorlyDesignedState(TypedDict):
    data: Any
    info: dict
```

### 2. Node Design

```python
# âœ… Good: Single responsibility, clear returns
def process_data(state: MyState) -> dict:
    """Process input data."""
    processed = transform(state["input"])
    return {"processed_data": processed}

# âŒ Bad: Multiple responsibilities, unclear
def do_everything(state):
    # Too many things happening
    pass
```

### 3. Error Handling

```python
# âœ… Good: Explicit error handling
def robust_node(state: MyState) -> dict:
    try:
        result = risky_operation()
        return {"result": result, "status": "success"}
    except SpecificError as e:
        return {"error": str(e), "status": "failed"}
```

### 4. Testing

```python
# Test individual nodes
def test_agent_node():
    state = {"messages": [HumanMessage(content="test")]}
    result = agent_node(state)
    assert "messages" in result

# Test full graph
def test_full_workflow():
    app = build_graph()
    result = app.invoke({"messages": [("user", "hello")]})
    assert result["status"] == "complete"
```

### 5. Configuration Management

```python
# Use configurable parameters
def create_agent(config: dict):
    model = ChatOpenAI(
        model=config.get("model", "gpt-4"),
        temperature=config.get("temperature", 0)
    )
    return create_react_agent(model, tools)
```

---

## Real-World Use Cases

### 1. Customer Support Bot

```python
# Multi-step customer support with escalation
- Greet customer
- Classify intent (FAQ, Technical, Billing)
- Route to appropriate handler
- If unresolved, escalate to human
- Collect feedback
```

### 2. Research Assistant

```python
# Autonomous research agent
- Accept research topic
- Search multiple sources
- Synthesize information
- Generate report
- Accept feedback and iterate
```

### 3. Code Review System

```python
# Multi-agent code review
- Analyzer: Parse code structure
- Security Reviewer: Check vulnerabilities
- Style Checker: Enforce conventions
- Summarizer: Compile findings
```

### 4. Content Pipeline

```python
# Content creation workflow
- Topic Research Agent
- Outline Generator
- Draft Writer
- Editor/Reviewer
- SEO Optimizer
- Human Approval Gate
```

### 5. Data Processing Pipeline

```python
# ETL with intelligence
- Data Ingestion
- Quality Validation
- Transformation (AI-assisted)
- Error Correction Loop
- Output Generation
```

---

## Getting Started

### Installation

```bash
# Core package
pip install langgraph

# With all dependencies
pip install langgraph langchain langchain-openai

# For visualization
pip install pygraphviz
```

### Minimal Example

```python
from langgraph.graph import StateGraph, START, END
from typing import TypedDict

# 1. Define State
class State(TypedDict):
    input: str
    output: str

# 2. Define Node
def process(state: State) -> dict:
    return {"output": state["input"].upper()}

# 3. Build Graph
graph = StateGraph(State)
graph.add_node("process", process)
graph.add_edge(START, "process")
graph.add_edge("process", END)

# 4. Compile and Run
app = graph.compile()
result = app.invoke({"input": "hello world"})
print(result["output"])  # HELLO WORLD
```

### Your First Agent

```python
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool

@tool
def get_weather(city: str) -> str:
    """Get weather for a city."""
    return f"The weather in {city} is sunny, 72Â°F"

model = ChatOpenAI(model="gpt-4")
agent = create_react_agent(model, [get_weather])

result = agent.invoke({
    "messages": [("user", "What's the weather in San Francisco?")]
})
print(result["messages"][-1].content)
```

### Visualizing Your Graph

```python
from IPython.display import Image, display

# Get graph visualization
graph_image = app.get_graph().draw_mermaid_png()
display(Image(graph_image))
```

---

## Resources for Learning

### Official Resources

| Resource | Link | Description |
|----------|------|-------------|
| **Documentation** | https://langchain-ai.github.io/langgraph/ | Official docs |
| **GitHub** | https://github.com/langchain-ai/langgraph | Source code |
| **Examples** | https://github.com/langchain-ai/langgraph/tree/main/examples | Code examples |
| **LangChain Academy** | https://academy.langchain.com | Free courses |

### Tutorials and Courses

1. **LangGraph Quickstart** - Official getting started guide
2. **Building Agents** - Step-by-step agent tutorial
3. **Multi-Agent Systems** - Complex orchestration patterns
4. **Production Deployment** - LangGraph Platform guide

### Community

- **Discord**: LangChain Discord server
- **Twitter/X**: @LangChainAI
- **YouTube**: LangChain channel

### Books and Articles

- LangChain documentation (includes LangGraph)
- Medium articles on LangGraph patterns
- Dev.to tutorials

---

## Roadmap and Future

### Current Developments (as of late 2024)

- **LangGraph Platform**: Managed deployment solution
- **LangGraph Studio**: Visual debugging tool
- **Enhanced Streaming**: Better real-time capabilities
- **Improved Persistence**: More backend options

### Coming Features

- Better multi-tenant support
- Enhanced visualization tools
- More prebuilt patterns
- Performance optimizations

---

## Quick Reference

### Essential Imports

```python
from langgraph.graph import StateGraph, START, END, add_messages
from langgraph.prebuilt import create_react_agent, ToolNode
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, Annotated
```

### Common Patterns

```python
# Conditional routing
graph.add_conditional_edges("node", router_fn, {"option1": "node1", "option2": END})

# Checkpointing
app = graph.compile(checkpointer=MemorySaver())

# Thread-based execution
config = {"configurable": {"thread_id": "unique_id"}}
result = app.invoke(input, config)

# Streaming
for event in app.stream(input, stream_mode="values"):
    print(event)

# Interrupt/Resume
app = graph.compile(interrupt_before=["sensitive_node"])
```

---

## Conclusion

LangGraph represents a significant evolution in how we build AI applications. By providing:

- **Explicit state management**
- **Cyclic graph support**
- **Fine-grained controllability**
- **Built-in persistence**
- **Human-in-the-loop capabilities**

It enables developers to build sophisticated, production-ready AI agents and multi-agent systems that were previously difficult or impossible with simpler frameworks.

As you embark on your LangGraph journey in 2025, remember:

1. **Start simple**: Begin with basic graphs and add complexity
2. **Understand state**: State management is the core concept
3. **Embrace cycles**: They're what make LangGraph powerful
4. **Use checkpoints**: They enable debugging and resilience
5. **Build iteratively**: Test each node before combining

Happy building! ðŸš€

---

*Last Updated: December 2024*
*Version: LangGraph 0.2.x*
*adding more content*

